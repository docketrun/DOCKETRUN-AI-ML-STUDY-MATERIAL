{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Copyright and Author Information**\n",
        "\n",
        "Copyright © [2024] Docketrun Tech Private Limited. All rights reserved.\n",
        "\n",
        "This notebook is open-sourced and available under the [MIT License](https://opensource.org/licenses/MIT).\n",
        "\n",
        "Author: Yahiya Mulla\n",
        "\n",
        "This Colab notebook is provided for educational and informational purposes only. You are free to use, modify, and distribute it, provided that proper attribution is given.\n",
        "\n",
        "**Disclaimer:** The information in this notebook is provided \"as is,\" without warranty of any kind. The authors or the company do not accept any responsibility for errors or omissions in the content."
      ],
      "metadata": {
        "id": "QdPQ7GUdYOKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image processing**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BldlRmvQ3yNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**\n",
        "*   **from google.colab import files**: This imports the files module from the Google\n",
        "Colab library, which allows you to upload files (e.g., images) from your local machine to the Colab environment.\n",
        "*   **import cv2**: This imports the OpenCV library, which is used for image processing tasks such as reading, writing, and manipulating images.\n",
        "*   **from matplotlib import pyplot as plt**: This imports the pyplot module from the matplotlib library, which is used for displaying images and creating plots."
      ],
      "metadata": {
        "id": "TBNoRQOGoRjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "0vqWnU5tYuPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Upload the Image**\n",
        "**uploaded = files.upload()**:\n",
        "\n",
        "This line of code opens a file dialog in the Colab notebook, allowing you to select and upload an image from your local machine. The variable **uploaded** is a dictionary where the keys are the filenames of the uploaded files, and the values are the file data (in bytes). After uploading, you can access the image using the filename."
      ],
      "metadata": {
        "id": "msqgXJ43pBnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the image\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "hjYDgwGApfMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reading the image**\n",
        "**cv2.imread()** reads an image from the file system and loads it into a variable. '**image.jpeg**' is the file path of the image you want to load.\n",
        "\n",
        "This function reads the image and returns it as a NumPy array. The image is loaded in **BGR** (Blue, Green, Red) format by default, which is the standard color format used by OpenCV."
      ],
      "metadata": {
        "id": "NdcraSW4pwlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('image.jpeg')"
      ],
      "metadata": {
        "id": "7unmQYs-qUis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Converting Color Spaces**\n",
        "\n",
        "**cv2.cvtColor(image, cv2.COLOR_BGR2RGB)**:\n",
        "\n",
        "*   **image**: The image loaded in BGR format.\n",
        "*   **cv2.COLOR_BGR2RGB**: This is a flag that specifies the conversion from BGR to RGB color space. cv2.COLOR_BGR2RGB indicates that OpenCV should convert the image from BGR (used by OpenCV) to RGB (used by Matplotlib).\n",
        "*   **cv2.cvtColor()**: This function performs the color space conversion and returns the image in RGB format.\n",
        "\n",
        "**plt.imshow(image_rgb)**:\n",
        "\n",
        "This function displays the image using Matplotlib. **image_rgb** is the image in RGB format, which is compatible with Matplotlib’s imshow() function.\n",
        "\n",
        "**plt.axis('off')**:\n",
        "\n",
        "This function turns off the axis labels and ticks on the plot. It makes the display cleaner by hiding the axes around the image.\n",
        "\n",
        "**plt.show()**:\n",
        "\n",
        "This function renders the plot and displays it in the output cell. It is necessary to call this function to actually visualize the image in Colab notebooks."
      ],
      "metadata": {
        "id": "HWN-qitOZoj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert BGR to RGB for displaying with matplotlib\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wjq-wsEkZY3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets try converting the image into **grayscale**\n",
        "\n",
        "**cv2.COLOR_BGR2GRAY** is the color conversion code used to specify that the image should be converted from **BGR** (Blue, Green, Red) to **GRAY** (grayscale)."
      ],
      "metadata": {
        "id": "fUZf2vWdajuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image to grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Display the grayscale image\n",
        "plt.imshow(gray_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cT210sqBapjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Resizing an Image**\n",
        "\n",
        "**image.shape** returns a tuple representing the dimensions of the image."
      ],
      "metadata": {
        "id": "RYv6tbjvbb6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the shape of the image\n",
        "print( image.shape )"
      ],
      "metadata": {
        "id": "cfOawxzzbfJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**cv2.resize()** function is used to change the size of an image to the specified width and height.\n",
        "\n",
        "**image** is the input image that you want to resize and **(500, 500)** tuple specifies the new size of the image i.e 500 width and 500 height."
      ],
      "metadata": {
        "id": "EgjtQ4CtsqYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resizing the image to 500 x 500\n",
        "resized_image = cv2.resize(image, (500, 500))\n",
        "\n",
        "# Convert BGR to RGB for displaying with matplotlib\n",
        "resized_image_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the resized image\n",
        "plt.imshow(resized_image_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# printing the shape of the image\n",
        "print( resized_image.shape )"
      ],
      "metadata": {
        "id": "YoXItDqEbwUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Image Blurring**\n",
        "\n",
        "**cv2.GaussianBlur()** function applies a **Gaussian blur** to an image. Gaussian blur is a common image processing technique used to **reduce noise** **and** **detail** in an image. It works by averaging the pixels within a kernel to smooth out rapid changes in intensity.\n",
        "\n",
        "**image** is the input image to which the Gaussian blur will be applied and **(15, 15)** tuple specifies the size of the Gaussian kernel. In this case, the kernel is 15 pixels wide and 15 pixels high.\n",
        "\n",
        "**NOTE: The kernel size must be positive and odd. Larger kernel sizes result in more blurring.**\n",
        "\n",
        "**0** parameter specifies the standard deviation in the X direction (**sigmaX**) for the Gaussian kernel. **sigmaX** Controls the extent of the blur in the X direction. The default value of 0 means that the function will calculate an appropriate value based on the kernel size."
      ],
      "metadata": {
        "id": "D47OV7focKC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Gaussian Blur\n",
        "blurred_image = cv2.GaussianBlur(image, (15, 15), 0)\n",
        "\n",
        "# Convert BGR to RGB for displaying with matplotlib\n",
        "blurred_image_rgb = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the blurred image\n",
        "plt.imshow(blurred_image_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p2Un4od-cMFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Edge Detection**\n",
        "\n",
        "**cv2.Canny()** function is used to **detect edges** in an image using the **Canny edge detection algorithm**. This algorithm is a popular method for edge detection due to its accuracy and efficiency.\n",
        "\n",
        "**gray_image** is the input image on which edge detection is performed. Edge detection generally works on grayscale images as color information is not required for finding edges.\n",
        "\n",
        "**100** parameter is the first threshold for the edge detection algorithm. It is used to determine whether a gradient magnitude is strong enough to be considered an edge. Values below this threshold are discarded.\n",
        "\n",
        "**120** parameter is the second threshold for the edge detection algorithm. It is used to identify strong edges. Pixels with gradient magnitudes above this threshold are considered strong edges, while those between the two thresholds are considered weak edges.\n"
      ],
      "metadata": {
        "id": "PMiUHTuTceSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will use canny edge detector to detect the edges.\n",
        "edges = cv2.Canny(gray_image, 100, 120)\n",
        "\n",
        "# Display the edges\n",
        "plt.imshow(edges, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ARONAWUcf9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Thresholding**\n",
        "\n",
        "**cv2.threshold()** function is used to apply a **thresholding operation** to an image. Thresholding converts a **grayscale image** to a **binary image (black and white)** based on a specified threshold value.\n",
        "\n",
        "**gray_image** is the input grayscale image to which the thresholding operation will be applied.\n",
        "\n",
        "**100** is the threshold value used to classify pixel values into two categories. Pixels with intensity values **greater than or equal** to this threshold will be set to the **maximum value (255)**, while pixels with intensity values **less than** this threshold will be set to **0**.\n",
        "\n",
        "**255** is the maximum intensity value to be assigned to pixels that meet the threshold condition."
      ],
      "metadata": {
        "id": "L9kwDoErc0l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply binary thresholding\n",
        "_, binary_image = cv2.threshold(gray_image, 100, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "# Display the binary image\n",
        "plt.imshow(binary_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hiTLRHBIc2I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Image Cropping**\n",
        "\n",
        "**image** is the input image from which you want to crop a specific region. It is represented as a **NumPy array** in OpenCV, where the array dimensions correspond to the height, width, and color channels of the image.\n",
        "\n",
        "General syntax is **image[y1:y2, x1:x2]** where **25:174** represents **y1:y2** and **80:185** represents **x1:x2**."
      ],
      "metadata": {
        "id": "nGtvAEngc-z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crop the image (y1:y2, x1:x2)\n",
        "cropped_image = image[25:174, 80:185]\n",
        "\n",
        "# Convert BGR to RGB for displaying with matplotlib\n",
        "cropped_image_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the cropped image\n",
        "plt.imshow(cropped_image_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LDDDS_OTdAs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Drawing on Images**\n",
        "\n",
        "**image_copy = image.copy()**: copy() method is used to create a deep copy of a NumPy array. In the context of image processing with OpenCV, it creates a new image that is a duplicate of the original image.\n",
        "\n",
        "**cv2.rectangle()** function is used to draw a rectangle on an image. **image_copy** is the image on which the rectangle will be drawn, **(50, 50)** tuple represents the coordinates of the top-left corner of the rectangle, **(185, 174)** tuple represents the coordinates of the bottom-right corner of the rectangle, **(0, 255, 0)** tuple represents the color of the rectangle in BGR (Blue, Green, Red) format and **3** parameter specifies the thickness of the rectangle’s border in pixels."
      ],
      "metadata": {
        "id": "omlqOebxdr6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating copy of the image\n",
        "image_copy = image.copy()\n",
        "\n",
        "# Draw a rectangle on the image\n",
        "cv2.rectangle(image_copy, (50, 50), (185, 174), (0, 255, 0), 3)\n",
        "\n",
        "# Convert BGR to RGB for displaying with matplotlib\n",
        "image_rgb_with_shapes = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image with drawings\n",
        "plt.imshow(image_rgb_with_shapes)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oQJE3TK_dvAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**cv2.circle()** function is used to draw a circle on an image. **image_copy** is the image on which the circle will be drawn, **(100, 100)** tuple represents the coordinates of the center of the circle, **100** parameter specifies the radius of the circle in pixels, **(255, 0, 0)** tuple represents the color of the circle in BGR (Blue, Green, Red) format and **-1** parameter specifies the thickness of the circle’s border. A value of -1 means the circle will be filled with the specified color. If a positive value is used, it specifies the thickness of the circle’s border, and the circle will not be filled."
      ],
      "metadata": {
        "id": "ParImToky6Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating copy of the image\n",
        "image_copy = image.copy()\n",
        "\n",
        "# Draw a circle on the image\n",
        "cv2.circle(image_copy, (100, 100), 100, (255, 0, 0), -1)\n",
        "\n",
        "# Convert BGR to RGB for displaying with matplotlib\n",
        "image_rgb_with_shapes = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image with drawings\n",
        "plt.imshow(image_rgb_with_shapes)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IerBJ1-Sea_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Flipping an image**\n",
        "\n",
        "**cv2.flip()** function is used to flip or mirror an image along a specified axis. This function allows you to perform horizontal and vertical flips. **image** is the input image to be flipped and **1** parameter specifies the axis along which to flip the image. Here **0** represents Flip vertically (around the x-axis), **1** represents Flip horizontally (around the y-axis) and **-1** represents Flip both vertically and horizontally.\n",
        "\n",
        "**plt.figure(figsize=(10, 5))** creates a new figure (or window) for plotting. The figsize parameter specifies the dimensions of the figure in inches.\n",
        "\n",
        "**plt.subplot(1, 3, 1)** function defines a subplot within the figure. It allows you to arrange multiple plots in a grid layout. The first parameter (1) specifies the number of rows in the grid, The second parameter (3) specifies the number of columns in the grid and The third parameter (1) specifies the index of the current subplot in the grid layout (in this case, the first subplot)."
      ],
      "metadata": {
        "id": "mcFLnggulnUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flip horizontally\n",
        "flipped_horizontally = cv2.flip(image, 1)\n",
        "\n",
        "# Flip vertically\n",
        "flipped_vertically = cv2.flip(image, 0)\n",
        "\n",
        "# Flip both horizontally and vertically\n",
        "flipped_both = cv2.flip(image, -1)\n",
        "\n",
        "# Step 3: Convert BGR to RGB for displaying with matplotlib\n",
        "flipped_horizontally_rgb = cv2.cvtColor(flipped_horizontally, cv2.COLOR_BGR2RGB)\n",
        "flipped_vertically_rgb = cv2.cvtColor(flipped_vertically, cv2.COLOR_BGR2RGB)\n",
        "flipped_both_rgb = cv2.cvtColor(flipped_both, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the original and flipped images\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(flipped_horizontally_rgb)\n",
        "plt.axis('off')\n",
        "plt.title('Flipped Horizontally')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(flipped_vertically_rgb)\n",
        "plt.axis('off')\n",
        "plt.title('Flipped Vertically')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(flipped_both_rgb)\n",
        "plt.axis('off')\n",
        "plt.title('Flipped Both')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IQ1s4vQelsuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adding two images**\n",
        "\n",
        "**cv2.add()** function performs **pixel-wise addition** of two images. This means that the function adds the corresponding pixel values from **image1** and **image2** to produce a new image **added_image**. It also supports adding a **scalar value** to an image. This operation adds the scalar value to each channel (BGR) of every pixel in the image."
      ],
      "metadata": {
        "id": "OmBi1s3koLQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = image.copy()\n",
        "image2 = flipped_horizontally.copy()\n",
        "\n",
        "print( \"image1 shape: {0}, image2 shape: {1}\".format( image1.shape, image2.shape ) )\n",
        "\n",
        "# Add the images\n",
        "added_image = cv2.add(image1, image2)\n",
        "\n",
        "# Add a scalar value to each pixel in the image (increase brightness)\n",
        "brightened_image = cv2.add(image1, 80)\n",
        "\n",
        "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "added_image = cv2.cvtColor(added_image, cv2.COLOR_BGR2RGB)\n",
        "brightened_image = cv2.cvtColor(brightened_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the original and flipped images\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(image1)\n",
        "plt.axis('off')\n",
        "plt.title('image 1')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(image2)\n",
        "plt.axis('off')\n",
        "plt.title('image 2')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(added_image)\n",
        "plt.axis('off')\n",
        "plt.title('Added image')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(brightened_image)\n",
        "plt.axis('off')\n",
        "plt.title('brightened image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kjxl8kvCllYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Subtracting two images**\n",
        "\n",
        "**cv2.subtract()** function performs **pixel-wise subtraction** of two images. This means that for each corresponding pixel in the two images, the function subtracts the pixel value in **image2** from the pixel value in **image1**. It also supports subtracting a scalar value to an image. This operation removes the scalar value to each channel (BGR) of every pixel in the image."
      ],
      "metadata": {
        "id": "dnOA14RbpBoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = image.copy()\n",
        "image2 = flipped_horizontally.copy()\n",
        "\n",
        "# Subtract the second image from the first\n",
        "subtracted_image = cv2.subtract(image1, image2)\n",
        "\n",
        "# Subtract the second image from the first\n",
        "reduced_brightness = cv2.subtract(image1, 80)\n",
        "\n",
        "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "subtracted_image = cv2.cvtColor(subtracted_image, cv2.COLOR_BGR2RGB)\n",
        "reduced_brightness = cv2.cvtColor(reduced_brightness, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the original and flipped images\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(image1)\n",
        "plt.axis('off')\n",
        "plt.title('image 1')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(image2)\n",
        "plt.axis('off')\n",
        "plt.title('image 2')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(subtracted_image)\n",
        "plt.axis('off')\n",
        "plt.title('subtracted image')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(reduced_brightness)\n",
        "plt.axis('off')\n",
        "plt.title('brightness reduced image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qUa2ITv_pV4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Multiplication of two images**\n",
        "\n",
        "**cv2.multiply()** function performs element-wise (pixel-by-pixel) multiplication of two images. Each pixel value in the output image is the product of the corresponding pixel values from **image1** and **image2**. It also supports multiplying an image by a scalar value. When you multiply an image by a scalar, every pixel in the image is multiplied by that scalar value."
      ],
      "metadata": {
        "id": "HzujH3csrDBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = image.copy()\n",
        "image2 = flipped_horizontally.copy()\n",
        "\n",
        "# Multiply the two images\n",
        "multiplied_image = cv2.multiply(image1, image2)\n",
        "\n",
        "# Multiply the image by a scalar value (increase contrast)\n",
        "high_contrast_image = cv2.multiply(image1, 2.0)\n",
        "\n",
        "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "multiplied_image = cv2.cvtColor(multiplied_image, cv2.COLOR_BGR2RGB)\n",
        "high_contrast_image = cv2.cvtColor(high_contrast_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the original and flipped images\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(image1)\n",
        "plt.axis('off')\n",
        "plt.title('image 1')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(image2)\n",
        "plt.axis('off')\n",
        "plt.title('image 2')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(multiplied_image)\n",
        "plt.axis('off')\n",
        "plt.title('multiplied image')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(high_contrast_image)\n",
        "plt.axis('off')\n",
        "plt.title('high contrast image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i3ve5cworHJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Division of two images**\n",
        "\n",
        "**cv2.divide()** function performs pixel-by-pixel **division** of two images. This means that for each corresponding pixel in the two images, the function divides the pixel value in **image1** by the pixel value in **image2**. It also support scalar division, where a single scalar value is used to divide each pixel in an image."
      ],
      "metadata": {
        "id": "yECCOUwhsbRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = image.copy()\n",
        "image2 = flipped_horizontally.copy()\n",
        "\n",
        "# Divide the first image by the second image\n",
        "divided_image = cv2.divide(image1, image2)\n",
        "\n",
        "# Divide the image by a scalar value (reduce contrast)\n",
        "low_contrast_image = cv2.divide(image1, 2.0)\n",
        "\n",
        "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
        "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
        "divided_image = cv2.cvtColor(divided_image, cv2.COLOR_BGR2RGB)\n",
        "low_contrast_image = cv2.cvtColor(low_contrast_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the original and flipped images\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.imshow(image1)\n",
        "plt.axis('off')\n",
        "plt.title('image 1')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.imshow(image2)\n",
        "plt.axis('off')\n",
        "plt.title('image 2')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.imshow(divided_image)\n",
        "plt.axis('off')\n",
        "plt.title('division image')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.imshow(low_contrast_image)\n",
        "plt.axis('off')\n",
        "plt.title('low contrast image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2JtVeQwTsqr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Brightness vs. Contrast**\n",
        "\n",
        "**Brightness** and **contrast** are fundamental concepts in image processing, and they are often adjusted to improve the appearance of an image.\n",
        "\n",
        "**Brightness** refers to the overall lightness or darkness of an image. Adjusting the brightness changes the intensity of all the pixels in the image uniformly.\n",
        "\n",
        "**Contrast** refers to the difference in intensity between the darkest and brightest parts of an image. High contrast images have a wider range of intensity values (from dark to bright), whereas low contrast images appear more muted or washed out.\n",
        "\n",
        "Let us have the visualization."
      ],
      "metadata": {
        "id": "3OZDbloquFut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the original and flipped images\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.imshow(image1)\n",
        "plt.axis('off')\n",
        "plt.title('image 1')\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.imshow(brightened_image)\n",
        "plt.axis('off')\n",
        "plt.title('brightened image')\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.imshow(high_contrast_image)\n",
        "plt.axis('off')\n",
        "plt.title('high contrast image')\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.imshow(image1)\n",
        "plt.axis('off')\n",
        "plt.title('image 1')\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.imshow(reduced_brightness)\n",
        "plt.axis('off')\n",
        "plt.title('brightness reduced image')\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.imshow(low_contrast_image)\n",
        "plt.axis('off')\n",
        "plt.title('low contrast image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NMH6MyZvudQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**brightened** **image**: By adding a constant value to each pixel, the entire image becomes brighter.\n",
        "\n",
        "**brightness reduced image**: By subtracting a constant value from each pixel, the image becomes darker.\n",
        "\n",
        "**high contrast image**: By multiplying the pixel values by 2.0, the dark areas become darker, and the bright areas become brighter, increasing the contrast.\n",
        "\n",
        "**low contrast image**: By multiplying the pixel values by 2.0, the difference between the bright and dark areas is reduced, making the image appear more muted and grayish.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Hence,\n",
        "\n",
        "**Brightness** adjusts the overall lightness or darkness of an image by uniformly increasing or decreasing the pixel intensity.\n",
        "\n",
        "**Contrast** adjusts the difference between the light and dark areas of an image, either enhancing or diminishing the separation between these extremes."
      ],
      "metadata": {
        "id": "m7VbH35qwTre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Rotateing an image**\n",
        "\n",
        "**cv2.getRotationMatrix2D()** function computes the affine transformation matrix for rotating an image around a specified center by a given angle.\n",
        "*   **center** tuple represents the coordinates of the center of rotation. The rotation will occur around this point,\n",
        "*   **angle** parameter specifies the rotation angle in degrees. Positive values indicate counterclockwise rotation, while negative values indicate clockwise rotation and,\n",
        "*   **1.0** parameter specifies the scaling factor for the image. A value of 1.0 means no scaling (i.e., the image will maintain its original size after rotation). If the value is greater than 1.0, the image will be scaled up, and if less than 1.0, it will be scaled down.\n",
        "\n",
        "\n",
        "**cv2.warpAffine()** function applies an affine transformation to an image. This can include operations such as rotation, translation, and scaling.\n",
        "*   **image** is the input image to which the affine transformation will be applied.\n",
        "*   **rotation_matrix** is the 2x3 affine transformation matrix that specifies how the image should be transformed. It’s usually obtained from functions like cv2.getRotationMatrix2D(). In this case, it represents the rotation transformation.\n",
        "*   **(new_w, new_h)** tuple specifies the size of the output image (width and height). It defines the dimensions of the output image where the transformed image will be placed.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "abt7NekomsdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "angle = 45  # You can change this to any angle you want\n",
        "\n",
        "# Get the dimensions of the image\n",
        "(h, w) = image.shape[:2]\n",
        "\n",
        "# Define the center of the image\n",
        "center = (w // 2, h // 2)\n",
        "\n",
        "# Calculate the rotation matrix\n",
        "rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "\n",
        "# Perform the rotation with the new dimensions\n",
        "rotated_image = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
        "\n",
        "# Convert BGR to RGB for displaying with matplotlib\n",
        "rotated_image_rgb = cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the original and flipped images\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis('off')\n",
        "plt.title('Original image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(rotated_image_rgb)\n",
        "plt.axis('off')\n",
        "plt.title('Rotated image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FqU_HaDiQ9Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angle = 45  # You can change this to any angle you want\n",
        "\n",
        "# Get the dimensions of the image\n",
        "(h, w) = image.shape[:2]\n",
        "\n",
        "# Define the center of the image\n",
        "center = (w // 2, h // 2)\n",
        "\n",
        "# Calculate the rotation matrix\n",
        "rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "\n",
        "# Calculate the cosine and sine of the rotation matrix\n",
        "abs_cos = abs(rotation_matrix[0, 0])\n",
        "abs_sin = abs(rotation_matrix[0, 1])\n",
        "\n",
        "# Compute the new bounding dimensions of the image\n",
        "new_w = int((h * abs_sin) + (w * abs_cos))\n",
        "new_h = int((h * abs_cos) + (w * abs_sin))\n",
        "\n",
        "# Adjust the rotation matrix to consider the translation\n",
        "rotation_matrix[0, 2] += (new_w / 2) - center[0]\n",
        "rotation_matrix[1, 2] += (new_h / 2) - center[1]\n",
        "\n",
        "# Perform the rotation with the new dimensions\n",
        "rotated_image = cv2.warpAffine(image, rotation_matrix, (new_w, new_h))\n",
        "\n",
        "# Convert BGR to RGB for displaying with matplotlib\n",
        "rotated_image_rgb = cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the original and flipped images\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis('off')\n",
        "plt.title('Original image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(rotated_image_rgb)\n",
        "plt.axis('off')\n",
        "plt.title('Rotated image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1vTz1dIzmv7a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}